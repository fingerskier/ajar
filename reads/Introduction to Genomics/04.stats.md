# Statistics in Genomic Data Science

The central dogma of statistics is that we can use a sample to make inferences about a population. 

In the context of genomics, we are often interested in making inferences about the population of all cells in a tissue or all individuals in a species.
The central limit theorem tells us that the distribution of the mean of a sample will be approximately normal, even if the underlying distribution is not normal.


Dataset Components
1. raw data
2. tidy data
3. code book
4. recipe for data processing


Robert Gentleman, "Make big data as small as possible as quickly as possible."

plots

interactive analysis

MA / Bland-Altman plots

ridiculograms


determining sample size
- power analysis
- pilot study

Variability
- phenotypic
- measurement error
- biological

T-statistic
- difference between two groups
- difference between a group and a known value

Y - X / sqrt(Var(Y) + Var(X))

Var(x) = Sy^2 / N
Var(y) = Sx^2 / M


P-value ~ the probability of observing a test statistic at least as extreme as the one observed, given that the null hypothesis is true.
- 0.05

family-wise error rate (FWER) ~ the probability of making at least one type I error in a family of tests.
 FWER = 1 - (1 - alpha)^m  where alpha is the significance level and m is the number of tests.

false discovery rate (FDR) ~ the expected proportion of false positives among all significant tests.
 FDR = m0 / m  where m0 is the number of false positives and m is the number of significant tests.


confounder ~ a variable that is associated with both the exposure and the outcome, but is not on the causal pathway between them.

